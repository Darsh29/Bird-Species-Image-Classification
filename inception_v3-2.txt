# %%
# Import Data Science Libraries
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# Tensorflow Libraries
from tensorflow import keras
from tensorflow.keras import layers, models
from keras_preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.inception_v3 import InceptionV3

from data_generation import prepare_data

BATCH_SIZE = 64
TARGET_SIZE = (224, 224)

# %%
train_df, val_df, test_df = prepare_data()

# %%
train_generator = ImageDataGenerator(
                        rescale=1./255,
                        rotation_range=30,
                        brightness_range=[0.7,1.3],
                        zoom_range=0.3,
                        width_shift_range=0.2, 
                        height_shift_range=0.2,
                        horizontal_flip=True)

test_generator = ImageDataGenerator(rescale=1./255)

# Generate Training images
train_images = train_generator.flow_from_dataframe(
                        dataframe=train_df,
                        x_col='Filepath',
                        y_col='Label',
                        target_size=TARGET_SIZE,  # all images will be resized to TARGET_SIZE
                        interpolation='nearest',
                        color_mode='rgb',
                        class_mode='categorical',
                        classes=list(train_df['Label'].unique()),
                        batch_size=BATCH_SIZE,
                        shuffle=True,
                        seed=175)

# Generate Validation images
val_images = test_generator.flow_from_dataframe(
                    dataframe=val_df,
                    x_col='Filepath',
                    y_col='Label',
                    target_size=TARGET_SIZE,  # all images will be resized to TARGET_SIZE
                    interpolation='nearest',
                    color_mode='rgb',
                    class_mode='categorical',
                    classes=list(train_df['Label'].unique()),
                    batch_size=BATCH_SIZE,
                    shuffle=True,
                    seed=42)

# Generate test images
test_images = test_generator.flow_from_dataframe(
                    dataframe=test_df,
                    x_col='Filepath',
                    y_col='Label',
                    target_size=TARGET_SIZE,  # all images will be resized to TARGET_SIZE
                    interpolation='nearest',
                    color_mode='rgb',
                    class_mode='categorical',
                    classes=list(train_df['Label'].unique()),
                    shuffle=False,
                    seed=42)

# %%
base_model = InceptionV3(weights='inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', 
                        include_top=False, 
                        input_shape=(TARGET_SIZE[0], TARGET_SIZE[1],3))
base_model.trainable = False

add_model = models.Sequential()
add_model.add(base_model)
add_model.add(layers.GlobalAveragePooling2D())
# add_model.add(layers.Dropout(0.2))
add_model.add(layers.Dense(1024, activation='relu'))
add_model.add(layers.BatchNormalization())
add_model.add(layers.Dense(525, activation='softmax'))

model = add_model
opt = keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer=opt,
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])
model.summary()

# %%
callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="./model/inceptionv3_tl.keras",
        save_best_only=True,
        monitor="val_loss"), 
    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', 
                                      factor=0.2, 
                                      patience=3, 
                                      min_lr=1e-6),
    keras.callbacks.EarlyStopping(monitor='val_loss', 
                                  verbose=1,
                                  min_delta=0.05,
                                  patience=5)
                                      ]

history = model.fit(train_images, epochs=25, 
                    validation_data=val_images, callbacks=callbacks)
model.save_weights('./model/inceptionv3_tl.weights.h5') 

# %%
for i, layer in enumerate(base_model.layers):
   print(i, layer.name)

# we chose to train the top 2 inception blocks, i.e. we will freeze
# the first 249 layers and unfreeze the rest:
for layer in model.layers[:249]:
   layer.trainable = False
for layer in model.layers[249:]:
   layer.trainable = True

# %%
opt = keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer=opt,
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])

# %%
callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="./model/inceptionv3_tl_unfrozen.keras",
        save_best_only=True,
        monitor="val_loss"), 
    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', 
                                      factor=0.2, 
                                      patience=3, 
                                      min_lr=1e-6),
    keras.callbacks.EarlyStopping(monitor='val_loss', 
                                  verbose=1,
                                  min_delta=0.05,
                                  patience=5)
                                      ]

history = model.fit(train_images, epochs=50, 
                    validation_data=val_images, callbacks=callbacks)
model.save_weights('./model/inceptionv3_tl_unfrozen.weights.h5') 

# %%
model.evaluate(test_images)

# %%
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
# plt.ylim([0.8, 1])
plt.legend(loc='lower right')

# %%
y_pred = model.predict(test_images)

# %%
y_pred.argmax(axis=1).shape

# %%
import numpy as np
np.array(test_images.classes).shape

# %%
from sklearn.metrics import f1_score
f1_score(np.array(test_images.classes), y_pred.argmax(axis=1), average='weighted')

# %%



